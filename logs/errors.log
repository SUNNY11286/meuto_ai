2025-07-27 19:20:00 | ERROR    | src.training.trainer:train:414 | Training failed: Error in train_epoch: Caught DataLoadingError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "C:\Users\Rajeshsingh\Desktop\folders\Interview\meuto_ai\src\utils\exceptions.py", line 82, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Rajeshsingh\Desktop\folders\Interview\meuto_ai\src\data\dataset.py", line 99, in __getitem__
    image = self.transform(image)
  File "C:\Users\Rajeshsingh\AppData\Roaming\Python\Python39\site-packages\albumentations\core\composition.py", line 193, in __call__
    raise KeyError("You have to pass data to augmentations as named arguments, for example: aug(image=image)")
KeyError: 'You have to pass data to augmentations as named arguments, for example: aug(image=image)'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Rajeshsingh\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\utils\data\_utils\worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "C:\Users\Rajeshsingh\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\Rajeshsingh\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\Rajeshsingh\Desktop\folders\Interview\meuto_ai\src\utils\exceptions.py", line 88, in wrapper
    raise exception_type(
src.utils.exceptions.DataLoadingError: Error in __getitem__: 'You have to pass data to augmentations as named arguments, for example: aug(image=image)' (Context: function=__getitem__, args=(<src.data.dataset.TextImageDataset object at 0x00000262B481AFA0>, 2109), kwargs={}, original_exception=KeyError)
 (Context: function=train_epoch, args=(<src.training.trainer.AnomalyDetectionTrainer object at 0x0000020D66DF6760>,), kwargs={}, original_exception=DataLoadingError)
2025-07-27 19:21:36 | ERROR    | src.training.trainer:train:414 | Training failed: Error in train_epoch: Error in forward: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.06 GiB is allocated by PyTorch, and 133.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF (Context: function=forward, args=(ConvolutionalAutoencoder(
  (encoder): Encoder(
    (encoder_blocks): ModuleList(
      (0): Sequen, kwargs={}, original_exception=OutOfMemoryError) (Context: function=train_epoch, args=(<src.training.trainer.AnomalyDetectionTrainer object at 0x000002285B32E700>,), kwargs={}, original_exception=ModelError)
2025-07-27 19:23:01 | ERROR    | src.training.trainer:train:414 | Training failed: Error in train_epoch: Error in forward: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.06 GiB is allocated by PyTorch, and 133.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF (Context: function=forward, args=(ConvolutionalAutoencoder(
  (encoder): Encoder(
    (encoder_blocks): ModuleList(
      (0): Sequen, kwargs={}, original_exception=OutOfMemoryError) (Context: function=train_epoch, args=(<src.training.trainer.AnomalyDetectionTrainer object at 0x000002378820EAF0>,), kwargs={}, original_exception=ModelError)
2025-07-27 20:37:44 | ERROR    | src.training.trainer:train:414 | Training failed: Error in train_epoch: Error in forward: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.06 GiB is allocated by PyTorch, and 133.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF (Context: function=forward, args=(ConvolutionalAutoencoder(
  (encoder): Encoder(
    (encoder_blocks): ModuleList(
      (0): Sequen, kwargs={}, original_exception=OutOfMemoryError) (Context: function=train_epoch, args=(<src.training.trainer.AnomalyDetectionTrainer object at 0x0000027BF075AB20>,), kwargs={}, original_exception=ModelError)
